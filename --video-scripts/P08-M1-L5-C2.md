Hi everyone, **welcome** back. This week we're covering autoencoders. This is **a type of** network *architecture* to perform data compression, where the compression and decompression function**s** **are learned** itself. **not hand-engineered** by humans.

The general idea with autoenoders is to pass your input data **through** **an** encoder to make a **compressed** *representation* of the input. *Then* you pass the representation **through** a decoder to get back reconstructed data.

The encoder and decoder are both build with neural networks. The whole network is trained by minimizing the difference between input and output, like normal. In this way the middle layer will be **a compressed** *representation* of input data. **from which** you can reconstruct the **original** data. There will be some **loss** of information *of course*, because you have fewer unit, **basically**.

In practice, autoencoders are actually **worse** **at** compression than traditional **methods** like JPEGs, MP3s and MPEGs for video. Also autoencoders have problems generalizing data sets other **than what they were** **trained** on. *However*, *recently* they found use an image denoising and dimensionality reduction. In this *lesson* I'll show you how tp build autoencoders **in** tensorflow. **I'll** start with a simple example where we'll compress images. Then **since** this is image data we'll improve it by using convolutional layers. Cheers.